{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5dbakk-Yxau"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from hopfield import (\n",
    "    NonidentityRecon, DiscreteTimeHopfieldLayer, softsign)\n",
    "from mnist import load_mnist\n",
    "from lena import load_lena, binary_repr\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0QNHlhGAPX2"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (32, 32)  # XXX: test!\n",
    "# IMAGE_SIZE = (8, 8)\n",
    "BINARIZE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), _ = load_mnist(image_size=IMAGE_SIZE, binarize=BINARIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = load_lena()\n",
    "# num_bits = 2\n",
    "# x_train = tf.cast(\n",
    "#     x_train / 255 * 2 ** num_bits,\n",
    "#     'int32')\n",
    "# x_train = tf.reshape(binary_repr(x_train[..., 0]), [-1, 2 ** 11])\n",
    "# x_train = tf.cast(x_train, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 1024), dtype=float32, numpy=\n",
       "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBMRecon(NonidentityRecon):\n",
    "    \"\"\"Restricted Boltzmann machine (RBM) based non-identity re-constructor.\n",
    "\n",
    "    RBM -- LDPC -- AE\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Non-identity: The latent dimension `latent_dim` shall be smaller the\n",
    "        ambient dimension, for ensuring the non-identity of the re-constructor.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    * Introduction to low-density parity-check (LDPC) code:\n",
    "        1. https://medium.com/5g-nr/ldpc-low-density-parity-check-code-8a4444153934\n",
    "    * Introduction to Boltzmann machine:\n",
    "        2. https://medium.com/edureka/restricted-boltzmann-machine-tutorial-991ae688c154\n",
    "    * Relation between Boltzmann machine and auto-encoder:\n",
    "        3. https://www.cs.cmu.edu/~rsalakhu/talk_Simons_part2_pdf.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latent_dim : int\n",
    "    softsign : callable, optional\n",
    "        Soft version of `sign` function. Softness means that the output of the\n",
    "        function is hard version, while the gradient is smooth (i.e. custom\n",
    "        gradient).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 latent_dim,\n",
    "                 softsign=softsign,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.softsign = softsign\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['latent_dim'] = self.latent_dim\n",
    "        config['softsign'] = self.softsign\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        depth = input_shape[-1]\n",
    "        assert depth > self.latent_dim\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=[depth, self.latent_dim],\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True)\n",
    "        self.latent_bias = self.add_weight(\n",
    "            name='latent_bias',\n",
    "            shape=[self.latent_dim],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "        self.ambient_bias = self.add_weight(\n",
    "            name='ambient_bias',\n",
    "            shape=[depth],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        f = self.softsign\n",
    "        W, b, v = self.kernel, self.latent_bias, self.ambient_bias\n",
    "        z = f(x @ W + b)\n",
    "        y = f(z @ tf.transpose(W) + v)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hopfield import step\n",
    "\n",
    "\n",
    "def outer(x, y):\n",
    "    return x[..., :, tf.newaxis] * y[..., tf.newaxis, :]\n",
    "\n",
    "\n",
    "class RBMWithHebbianLearning(NonidentityRecon):\n",
    "    \"\"\"Restricted Boltzmann machine (RBM) based non-identity re-constructor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latent_dim : int\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 latent_dim,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.activation = lambda x: step(x, threshold=0, minval=-1, maxval=1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['latent_dim'] = self.latent_dim\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        depth = input_shape[-1]\n",
    "        assert depth > self.latent_dim\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=[depth, self.latent_dim],\n",
    "            initializer='zeros',\n",
    "            trainable=False)\n",
    "        self.latent_bias = self.add_weight(\n",
    "            name='latent_bias',\n",
    "            shape=[self.latent_dim],\n",
    "            initializer='zeros',\n",
    "            trainable=False)\n",
    "        self.ambient_bias = self.add_weight(\n",
    "            name='ambient_bias',\n",
    "            shape=[depth],\n",
    "            initializer='zeros',\n",
    "            trainable=False)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        f = self.activation\n",
    "        W, b, v = self.kernel, self.latent_bias, self.ambient_bias\n",
    "        z = f(x @ W + b)\n",
    "        new_x = f(z @ tf.transpose(W) + v)\n",
    "        \n",
    "        if training:\n",
    "            new_z = f(new_x @ W + b)\n",
    "            dW = tf.reduce_sum(outer(x, z) - outer(new_x, new_z),\n",
    "                               axis=0)\n",
    "            db = tf.reduce_sum(z - new_z, axis=0)\n",
    "            dv = tf.reduce_sum(x - new_x, axis=0)\n",
    "            W.assign_add(dW)\n",
    "            b.assign_add(db)\n",
    "            v.assign_add(dv)\n",
    "\n",
    "        return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_repeat, latent_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        DiscreteTimeHopfieldLayer(\n",
    "            # RBMRecon(latent_dim),\n",
    "            RBMWithHebbianLearning(latent_dim),\n",
    "            max_steps=20,\n",
    "            reg_factor=1),\n",
    "    ])\n",
    "    model.compile(optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "kbqJL6p9GjLe",
    "outputId": "e92d7d0f-3a91-42fe-c48a-9b051c9b0ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 433/7813 [>.............................] - ETA: 15:48 - loss: 0.3226"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-facbbe1b260f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = x_train[:100].numpy()\n",
    "\n",
    "ds0 = tf.data.Dataset.from_tensor_slices(X)\n",
    "ds = ds0.shuffle(10000).repeat(10000).batch(128)\n",
    "model = create_model(num_repeat=1, latent_dim=256)\n",
    "model.fit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discrete_time_hopfield_layer (None, 1024)              263425    \n",
      "=================================================================\n",
      "Total params: 263,425\n",
      "Trainable params: 0\n",
      "Non-trainable params: 263,425\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relax steps: 1\n",
      "0.0 => 2.0\n"
     ]
    }
   ],
   "source": [
    "# noised_X = X + np.random.normal(size=X.shape) * 0.3\n",
    "noised_X = np.where(np.random.random(size=X.shape) < 0.2, -X, X)\n",
    "recon_X = model.predict(noised_X)\n",
    "\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        print('Relax steps:', layer.final_step.numpy())\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "orig_err = noised_X - X\n",
    "err = recon_X - X\n",
    "print(f'{np.quantile(np.abs(orig_err), 0.98)} => '\n",
    "      f'{np.quantile(np.abs(err), 0.98)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hopfield_layer = None\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, DiscreteTimeHopfieldLayer):\n",
    "        hopfield_layer = layer\n",
    "\n",
    "original_W = hopfield_layer.non_identity_recon.kernel.numpy()\n",
    "\n",
    "# plot W's histogram\n",
    "plt.hist(original_W.reshape([-1]), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip the small value elements of the W\n",
    "clipped_W = np.where(np.abs(original_W) < 0.05, 0., original_W)\n",
    "hopfield_layer.non_identity_recon.kernel.assign(\n",
    "    tf.constant(clipped_W, dtype='float32'))\n",
    "\n",
    "# plot W's histogram, after clipping\n",
    "plt.hist(clipped_W.reshape([-1]), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the clipped model to test the de-noising effect\n",
    "\n",
    "recon_X = model.predict(noised_X)\n",
    "\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        print('Relax steps:', layer.final_step.numpy())\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "orig_err = noised_X - X\n",
    "err = recon_X - X\n",
    "print(f'{np.quantile(np.abs(orig_err), 0.98)} => '\n",
    "      f'{np.quantile(np.abs(err), 0.98)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip ratio\n",
    "\n",
    "clip_ratio = 1 - np.sum(clipped_W > 0) / np.sum(original_W > 0)\n",
    "print(clip_ratio, np.sum(clipped_W > 0) // (IMAGE_SIZE[0] * IMAGE_SIZE[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. RBM based (soft) binary re-constructor also provides the de-noising property for the discrete-time Hopfield network. Also, it solves the problem of the traditional dense re-constructor, the case where the input dimension is too small so that the perceptron cannot get enough capacity for learning sufficient many patterns. (Recall that simply duplicating the pattern will break the non-identity down for the traditional dense re-constructor. But it's fine in case of the RBM based re-constructor.)\n",
    "1. However, comparing with the traditional dense re-constructor, the de-noising effect, even though still persists, reduces.\n",
    "1. Using soft activation in training phase while hard one in other phase cannot gain the previous properties. Only with a soften hard-activation can it gain. The reason maybe that binarization of output will reduce the difficulty of learning, since this output, as the input of the next layer, is regularized for the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EHL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
